{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5a8faf0",
   "metadata": {},
   "source": [
    "# Extraction and creation of txt files containing articles\n",
    "Clemence SEBE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bad6320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as et \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ab3a16",
   "metadata": {},
   "source": [
    "## Extracting PMC items from the xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0245a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmcAll = et.parse('14_7_2023/q3_14_7_2023.xml')\n",
    "pmc = pmcAll.getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f020c3f",
   "metadata": {},
   "source": [
    "Intermediate function for extracting information and text from XML :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df308b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractText(part, sup=False):\n",
    "    txt = ''\n",
    "    if part.tag != 'fig' and part.tag != 'table' and part.tag != 'table-wrap':  \n",
    "        \n",
    "        if part.tag == 'list-item':\n",
    "            for subPart in part:\n",
    "                if subPart.tag != 'label':\n",
    "                    txt += '** ' + extractText(subPart) + '\\n'\n",
    "        else:\n",
    "            if sup:\n",
    "                txt += ' ['\n",
    "                \n",
    "            if part.text != None:\n",
    "                if len(part) == 0:\n",
    "                    txt += part.text\n",
    "                else: \n",
    "                    txt += (part.text).strip() + \" \"\n",
    "\n",
    "            for subPart in part:\n",
    "                if subPart.tag =='xref':\n",
    "                    txt = txt.strip() \n",
    "                if subPart.tag == 'ext-link':\n",
    "                    txt = txt.strip() + \" \"\n",
    "                    \n",
    "                if subPart.tag == 'sup':\n",
    "                    txt = txt.strip()\n",
    "                    txt += extractText(subPart, True)\n",
    "                else:\n",
    "                    txt += extractText(subPart)\n",
    "\n",
    "            if sup:\n",
    "                txt += ']'\n",
    "            if part.tail != None:\n",
    "                if len(part.tail.strip()) != 0:\n",
    "                    txt += part.tail\n",
    "    \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a3167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracTitle(body, tab, idx):\n",
    "    section = body.findall('sec')\n",
    "    for sec in section:\n",
    "        title = sec.find('title')\n",
    "        if title != None:\n",
    "            txt = extractText(title)\n",
    "               \n",
    "            new = tab\n",
    "            new.append([idx,txt])\n",
    "            extracTitle(sec, new , idx+1)\n",
    "        else:\n",
    "            extracTitle(sec,tab, idx+1)\n",
    "    return tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b060b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def whichSection(titres, wordsAccepted):\n",
    "    accepted = []\n",
    "    for i in range (len(titres)) :\n",
    "        word = titres[i][-1].lower()\n",
    "        for wA in wordsAccepted:\n",
    "            if word.find(wA) != -1:\n",
    "                ok = True\n",
    "                if titres[i][0] == 0:\n",
    "                    if not titres[i][-1] in accepted:\n",
    "                        accepted.append(titres[i][-1])\n",
    "                else:\n",
    "                    for j in range (i,-1,-1):\n",
    "                        if titres[j][0] == 0:\n",
    "                            if not titres[j][-1] in accepted:\n",
    "                                accepted.append(titres[j][-1])\n",
    "                            break\n",
    "            \n",
    "    return accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97549f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractTextSection(file, section):\n",
    "    for part in section:\n",
    "        if part.tag == 'fn-group':\n",
    "            extractTextSection(file,part) \n",
    "        if part.tag == 'title':\n",
    "            txt = '\\n\\n\\t' + extractText(part) + '\\n\\n'\n",
    "            file.write(txt)\n",
    "        if part.tag == 'p' or part.tag == 'fn':\n",
    "            txt = extractText(part) + '\\n'\n",
    "            file.write(txt)\n",
    "        if part.tag == 'list':\n",
    "            txt = extractText(part) \n",
    "            file.write(txt)\n",
    "        if part.tag == 'notes':\n",
    "            extractTextSection(file,part)\n",
    "        if part.tag == 'sec':\n",
    "            extractTextSection(file, part)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c26636",
   "metadata": {},
   "source": [
    "\"Main\" creating the various txt files that make up the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c87e32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wordsAccepted = ['implementation', 'material', 'method', 'operation', 'pipeline', 'workflow', 'tool', '\\u2003']\n",
    "access = 0\n",
    "nonAccess = 0\n",
    "dicoArticle = {}\n",
    "idx = 1\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"article\")\n",
    "    os.mkdir(\"article/all\")\n",
    "except:\n",
    "    None\n",
    "\n",
    "\n",
    "titre = []\n",
    "titleSection = open(\"sectionTitle.txt\", 'w')\n",
    "\n",
    "paternGit = '(https:\\/\\/)?(www\\.)?github\\.com\\/(\\w|\\/|-|_)*'\n",
    "\n",
    "df = pd.DataFrame(columns=['id','titre', 'pmid', 'pmc', 'doi', 'XMLaccess', 'git', 'language'])                   \n",
    "\n",
    "for article in pmc:\n",
    "    print(str(idx) + \"/\" + str(len(pmc)))\n",
    "    front = article.find('front')\n",
    "    body = article.find('body')\n",
    "    \n",
    "    #extract gloabal information on the article\n",
    "    dicoSubArticle = {}\n",
    "    dicoSubArticle[idx] = {}\n",
    "    articleMeta = front.find('article-meta')\n",
    "    temp = {}\n",
    "    for idA in articleMeta.findall('article-id'):\n",
    "        if not idA.attrib['pub-id-type'] in temp:\n",
    "            temp.update({idA.attrib['pub-id-type'] : idA.text})\n",
    "        else:\n",
    "            print('NORMALLY NO - NOT TWO ID DIFFERENT')\n",
    "            \n",
    "    for k in temp:\n",
    "        dicoSubArticle[idx][k] = temp[k]\n",
    "    \n",
    "    title = articleMeta.find('title-group')\n",
    "    txtTitle = []\n",
    "    for child in title:\n",
    "        if child.tag.find('title') != -1:\n",
    "            txt = extractText(child)\n",
    "            txtTitle.append(txt)\n",
    "    dicoSubArticle[idx]['title'] = txtTitle\n",
    "    \n",
    "    #  abstract\n",
    "    try:\n",
    "        string =  'article/all/' +  \"PMID\" + dicoSubArticle[idx]['pmid'] + '.all.txt' \n",
    "    except:\n",
    "        string =  'article/all/'  +  \"PMC\" + dicoSubArticle[idx]['pmc'] + '.all.txt' \n",
    "    fileAll = open(string,'w')\n",
    "    fileAll.write(dicoSubArticle[idx]['title'][0] + '\\n\\n')\n",
    "        \n",
    "    abstract = articleMeta.findall('abstract')\n",
    "    for i in range (len(abstract)):\n",
    "        if i > 0:\n",
    "            fileAll.write(\"\\n\" + \"Abstract \" + str(i) + ' :\\n')\n",
    "        else:\n",
    "            fileAll.write(\"Abstract :\\n\")\n",
    "        extractTextSection(fileAll, abstract[i])\n",
    "    fileAll.write(\"\\n\" + \"-\"*100 + \"\\n\")\n",
    "\n",
    "    \n",
    "    if body == None:\n",
    "        nonAccess += 1\n",
    "        dicoSubArticle[idx]['XMLaccess'] = 'No'\n",
    "        dicoSubArticle[idx]['git'] = ''\n",
    "        fileAll.close()\n",
    "        stringGit = ''\n",
    "        tabGit = []\n",
    "    else:\n",
    "        access += 1\n",
    "        dicoSubArticle[idx]['XMLaccess'] = 'Free'\n",
    "        \n",
    "        #extract the text - only some sections       \n",
    "        titres = extracTitle(body,[], 0)\n",
    "        string = str(idx) + \" \"+ dicoSubArticle[idx]['title'][0]\n",
    "        titleSection.write(string)\n",
    "        titleSection.write('\\n')\n",
    "        for t in titres:\n",
    "            titleSection.write('\\t'*t[0])\n",
    "            titleSection.write(t[1])\n",
    "            titleSection.write('\\n')\n",
    "        titleSection.write('\\n\\n')\n",
    "        \n",
    "        nameSection = whichSection(titres, wordsAccepted)\n",
    "        try:\n",
    "            string = 'article/' + str(idx) + \"_PMID\" + dicoSubArticle[idx]['pmid'] + '.txt'\n",
    "        except:\n",
    "            string = 'article/' + str(idx) + \"_PMC\" + dicoSubArticle[idx]['pmc'] + '.txt'\n",
    "        file = open(string,'w')\n",
    "        file.write(dicoSubArticle[idx]['title'][0] + '\\n')\n",
    "        \n",
    "        print(dicoSubArticle[idx]['title'][0])\n",
    "        section = body.findall('sec')\n",
    "        for sec in section:\n",
    "            title = sec.find('title')\n",
    "            if title != None:\n",
    "                txt = extractText(title)\n",
    "                if txt in nameSection:\n",
    "                    extractTextSection(file,sec)\n",
    "        file.close()\n",
    "        \n",
    "        #extract all the article\n",
    "        for sec in section:\n",
    "            extractTextSection(fileAll,sec)\n",
    "        \n",
    "        #and the section Data Availability if the article have one\n",
    "        fileAll.write(\"\\n\" + \"-\"*100 + \"\\n\")\n",
    "        back = article.find('back')\n",
    "        extractTextSection(fileAll, back)               \n",
    "            \n",
    "        fileAll.close() \n",
    "        \n",
    "        #extract github @ \n",
    "        try:\n",
    "            string =  'article/all/' +  \"PMID\" + dicoSubArticle[idx]['pmid'] + '.all.txt' \n",
    "        except:\n",
    "            string =  'article/all/'  + \"PMC\" + dicoSubArticle[idx]['pmc'] + '.all.txt' \n",
    "        fileR = open(string,'r')\n",
    "        txt = fileR.read()\n",
    "        tabGit = []\n",
    "        stringGit = ''\n",
    "        for match in re.finditer(paternGit, txt):\n",
    "            git = txt[match.span()[0]: match.span()[1]]\n",
    "            \n",
    "            if git[0] == 'h':\n",
    "                git = git[8:]\n",
    "            if git[0] == 'w':\n",
    "                git = git[4:]\n",
    "            if not git in tabGit:\n",
    "                tabGit.append(git)\n",
    "                stringGit += git + ' , '\n",
    "        stringGit = stringGit[:-(len(' , '))]\n",
    "        dicoSubArticle[idx]['git'] = stringGit\n",
    "        fileR.close()\n",
    "        \n",
    "            \n",
    "\n",
    "    try:\n",
    "        pmidid = dicoSubArticle[idx]['pmid'] \n",
    "    except :\n",
    "        pmidid = ''\n",
    "    try:\n",
    "        pmcid = dicoSubArticle[idx]['pmc'] \n",
    "    except :\n",
    "        pmcid = ''\n",
    "    try:\n",
    "        doiid = dicoSubArticle[idx]['doi'] \n",
    "    except :\n",
    "        doiid = ''\n",
    "        \n",
    "    df_new_row = pd.DataFrame([{'id':idx, 'titre':dicoSubArticle[idx]['title'][0], 'pmid':pmidid, 'pmc':pmcid, \n",
    "                'doi':doiid, 'XMLaccess':dicoSubArticle[idx]['XMLaccess'], 'git':dicoSubArticle[idx]['git']}])\n",
    "    \n",
    "    df = pd.concat([df, df_new_row], ignore_index=True)\n",
    "    \n",
    "    print(\"~~~~~~~~~~~~~~~~~\")\n",
    "    \n",
    "    #print(dicoSubArticle)\n",
    "    dicoArticle.update(dicoSubArticle)\n",
    "    idx += 1\n",
    "    \n",
    "\n",
    "titleSection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e3b3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"On {} articles, {} open access Articles and {} no XML open acess Articles\".format(len(pmc),access, nonAccess))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a930b660",
   "metadata": {},
   "source": [
    "# Deplacement des articles dans le bon dossier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8869ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'article/all/'\n",
    "listArticle = os.listdir(path)\n",
    "\n",
    "nbNextflow = 0\n",
    "nbSnakemake = 0\n",
    "nbBoth = 0\n",
    "nonAccess = 0\n",
    "\n",
    "\n",
    "for article in listArticle:\n",
    "    a = open(path + article, 'r')\n",
    "    name = article.replace(\".all.txt\", '')\n",
    "\n",
    "    try:\n",
    "        idxDf = list(np.where(df['pmid'] == name.replace('PMID',''))[0])[0]\n",
    "    except:\n",
    "        idxDf = list(np.where(df['pmc'] == name.replace('PMC',''))[0])[0]\n",
    "\n",
    "    txt = a.read()\n",
    "    idx = txt.find('-'*100)\n",
    "    abstract = txt[:idx].lower()\n",
    "\n",
    "    n = abstract.find('nextflow')\n",
    "    s = abstract.find('snakemake')\n",
    "    \n",
    "    if n != -1 and s == -1:\n",
    "        df.at[idxDf,'language']='Nextflow'\n",
    "        if df.iloc[idxDf]['XMLaccess'] == 'Free':\n",
    "            nbNextflow += 1\n",
    "\n",
    "    elif n == -1 and s != -1:\n",
    "        df.at[idxDf,'language']='Snakemake'\n",
    "        if df.iloc[idxDf]['XMLaccess'] == 'Free':\n",
    "            nbSnakemake += 1\n",
    "            \n",
    "            \n",
    "    elif n != -1 and s != -1:\n",
    "        nbBoth += 1\n",
    "        df.at[idxDf,'language']='Both'\n",
    "        \n",
    "    a.close()\n",
    "print(\"Number of articles describing Nextflow wf : {}\".format(nbNextflow))\n",
    "print(\"Number of articles describing Snakemake wf : {}\".format(nbSnakemake))\n",
    "print(\"Number of items with both Nextflow and Snakemake : {}\".format(nbBoth))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbc14e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_html('corpus.html',justify='center',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278b9fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770fbebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "853d8cc187a79f991de8eabec73c5211ab1440896105dc73dfdee74aa5462890"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
